{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below with the ▶| button above to set up this notebook, or type `SHIFT-ENTER`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir -U -q folium\n",
    "import pandas as pd\n",
    "import geojson\n",
    "import geopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from datascience import *\n",
    "from IPython.display import HTML, display, IFrame\n",
    "from folium import plugins\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from scripts.soc_module import *\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sociology 130 Module: \"The Neighborhood Project\"\n",
    "\n",
    "Welcome to the data science part of your project! You have gathered data and entered it [here](https://goo.gl/forms/eY1mephilS6VqAT83) from your assigned census tracts.  Now it's time to explore our class data and quantify our observations using Python, a popular programming language used in data science. \n",
    "\n",
    "You won't need any prior programming knowledge to do this! The purpose of this module is not to teach you programming, but rather to show you the power of these tools and give you the intuition for how they work. It also allows us to quickly produce summarizations of our data!\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0 - [Python and Jupyter Notebooks](#jupyter)\n",
    "\n",
    "1 - [Class Data](#yourdata)\n",
    "\n",
    "2 - [Our Metrics](#ourmetrics)\n",
    "\n",
    "3 - [Census Data](#census)\n",
    "\n",
    "4 - [Correlation](#correlation)\n",
    "\n",
    "5 - [Regression](#regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Introduction to Python and Jupyter Notebooks: <a id='jupyter'></a>\n",
    "\n",
    "## 1. Cells, Arithmetic, and Code\n",
    "In a notebook, each rectangle containing text or code is called a *cell*.\n",
    "\n",
    "Cells (like this one) can be edited by double-clicking on them. This cell is a text cell, written in a simple format called [Markdown](http://daringfireball.net/projects/markdown/syntax) to add formatting and section headings.  You don't need to worry about Markdown today, but it's a pretty fun+easy tool to learn.\n",
    "\n",
    "After you edit a cell, click the \"run cell\" button at the top that looks like ▶| to confirm any changes. (Try not to delete the instructions.) You can also press `SHIFT-ENTER` to run any cell or progress from one cell to the next.\n",
    "\n",
    "Other cells contain code in the Python programming language.  Running a code cell will execute all of the code it contains.\n",
    "\n",
    "Try running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now quickly go through some very basic functionality of Python, which we'll be using throughout the rest of this notebook.\n",
    "\n",
    "### 1.1 Arithmetic\n",
    "Quantitative information arises everywhere in data science. In addition to representing commands to `print` out lines, expressions can represent numbers and methods of combining numbers. \n",
    "\n",
    "The expression `3.2500` evaluates to the number 3.25. (Run the cell and see.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't necessarily always need to say \"`print`\", because Jupyter always prints the last line in a code cell. If you want to print more than one line, though, do specify \"`print`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3)\n",
    "4\n",
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many basic arithmetic operations are built in to Python, like `*` (multiplication), `+` (addition), `-` (subtraction), and `/` (division). There are many others, which you can find information about [here](http://www.inferentialthinking.com/chapters/03/1/expressions.html). Use parenthesis to specify the order of operations, which act according to PEMDAS, just as you may have learned in school. Use parentheses for a happy new year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 + (6 * 5 - (6 * 3)) ** 2 * (( 2 ** 3 ) / 4 * 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Variables\n",
    "\n",
    "We sometimes want to work with the result of some computation more than once. To be able to do that without repeating code everywhere we want to use it, we can store it in a variable with *assignment statements*, which have the variable name on the left, an equals sign, and the expression to be evaluated and stored on the right. In the cell below, `(3 * 11 + 5) / 2 - 9` evaluates to 10, and gets stored in the variable `result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (3 * 11 + 5) / 2 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions\n",
    "\n",
    "    \n",
    "One important form of an expression is the call expression, which first names a function and then describes its arguments. The function returns some value, based on its arguments. Some important mathematical functions are:\n",
    "\n",
    "| Function | Description                                                   |\n",
    "|----------|---------------------------------------------------------------|\n",
    "| `abs`      | Returns the absolute value of its argument                    |\n",
    "| `max`      | Returns the maximum of all its arguments                      |\n",
    "| `min`      | Returns the minimum of all its arguments                      |\n",
    "| `round`    | Round its argument to the nearest integer                     |\n",
    "\n",
    "Here are two call expressions that both evaluate to 3\n",
    "\n",
    "```python\n",
    "abs(2 - 5)\n",
    "max(round(2.8), min(pow(2, 10), -1 * pow(2, 10)))\n",
    "```\n",
    "\n",
    "These function calls first evaluate the expressions in the arguments (inside the parentheses), then evaluate the function on the results. `abs(2-5)` evaluates first to `abs(3)`, then returns `3`.\n",
    "\n",
    "A **statement** is a whole line of code.  Some statements are just expressions, like the examples above, that can be broken down into its subexpressions which get evaluated individually before evaluating the statement as a whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Calling functions\n",
    "\n",
    "The most common way to combine or manipulate values in Python is by calling functions. Python comes with many built-in functions that perform common operations.\n",
    "\n",
    "For example, the `abs` function takes a single number as its argument and returns the absolute value of that number.  The absolute value of a number is its distance from 0 on the number line, so `abs(5)` is 5 and `abs(-5)` is also 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions can be called as above, putting the argument in parentheses at the end, or by using \"dot notation\", and calling the function after finding the arguments, as in the cell immediately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1, 2, 5]  # a list of items, in this case, numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums.reverse()  # reverses the item order\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Class Data<a id='yourdata'></a>\n",
    "\n",
    "We can read in the data you submitted through the form by asking Google for the form information and turning it into a table. Any of the confusing lines here are just fixing data formats so that Python can better understand our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = pd.read_csv('SP18 Social Disorder.csv', index_col=None)\n",
    "class_data['Census Tract'] = class_data['Census Tract'].apply(fix_tract)  # fix census tract data type\n",
    "\n",
    "# rekey yes and no responses\n",
    "for c in class_data.columns:\n",
    "    if \"Yes\" in set(class_data[c]):\n",
    "        class_data[c] = class_data[c].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "# limit to submissions from Spring 2018\n",
    "class_data['Timestamp'] = [datetime.strptime(time, '%m/%d/%Y %H:%M') for time in class_data['Timestamp']]\n",
    "class_data = class_data[[time.year == 2018 for time in class_data['Timestamp']]]\n",
    "class_data = class_data.reset_index().drop('index', axis = 1)\n",
    "\n",
    "image_data = class_data.iloc[:, 24:]\n",
    "image_data = image_data.rename(columns = { \n",
    "    'Full Address of Block Face in Image #1 (Street Number, Street Name, City, State, Zip Code). E.g.: 2128 Oxford Street, Berkeley, CA, 94704.': 'Full Address of Photo #1 Location',\n",
    "    'Full Address of Block Face in Image #2 (Street Number, Street Name, City, State, Zip Code). E.g.: 2128 Oxford Street, Berkeley, CA, 94704.': 'Full Address of Photo #2 Location',\n",
    "    'Full Address of Block Face in Image #3 (Street Number, Street Name, City, State, Zip Code). E.g.: 2128 Oxford Street, Berkeley, CA, 94704.': 'Full Address of Photo #3 Location',\n",
    "    'Full Address of Block Face in Image #4 (Street Number, Street Name, City, State, Zip Code). E.g.: 2128 Oxford Street, Berkeley, CA, 94704.': 'Full Address of Photo #4 Location',\n",
    "    'Full Address of Block Face in Image #5 (Street Number, Street Name, City, State, Zip Code). E.g.: 2128 Oxford Street, Berkeley, CA, 94704.': 'Full Address of Photo #5 Location'\n",
    "})\n",
    "\n",
    "image_data['Census Tract'] = class_data['Census Tract']\n",
    "\n",
    "class_data = class_data.iloc[:, :24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of columns! Now that our data is inside the `class_data` variable, we can ask that varible for some information. We can get a list of the column names with the `.columns` attribute of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's clean up the data a little bit. We can use '.drop' to remove extra columns and '.rename' to create shorter labels for our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = class_data.drop([\n",
    "    'House Number', \n",
    "    'What drinking establishments are on the block face? (check all that apply)',\n",
    "    'What kind of signs are visible? (check all that apply)',\n",
    "    'Are there any recreational facilities on the block face?',\n",
    "    'Other thoughts or comments'\n",
    "    ], axis = 1)\n",
    "\n",
    "class_data = class_data.rename(columns= {\n",
    "    'On a scale of 1 - 5, where 1 is \"None\" and 5 is \"A Lot\", how many empty beer or liquor bottles are visible in streets, yards, or alleys? ': 'Amount of Visible Empty Liquor Bottles [Scale: 1 (None) to 5 (A Lot)]', \n",
    "    'On a scale of 1 - 5, where 1 is \"None\" and 5 is \"A Lot\",  how many cigarette or cigar butts or discarded cigarette packages  are on the sidewalk or in the gutters? ': 'Amount of Visible Cigarette Debris [Scale: 1 (None) to 5 (A Lot)]',\n",
    "    'On a scale of 1 - 5, where 1 is \"None\" and 5 is \"A Lot\",  how many condoms are present on the sidewalk, in the gutters, or street of block face? ': 'Amount of Visible Condoms [Scale: 1 (None) to 5 (A Lot)]',\n",
    "    'On a scale of 1 - 5, where 1 is \"None\" and 5 is \"A Lot\", how much garbage, litter, or broken glass in the street or on the sidewalks? ': 'Amount of Visible Trash [Scale: 1 (None) to 5 (A Lot)]',\n",
    "    'On a scale of 1-5 where 1 is \"Friendly Responses / Greetings / Helpful\" and 5 is \"Treated with Suspicion\", How were you regarded by the people in the block face?': 'Attitude of Residents [Scale: 1 (Friendly and Helpful) to 5 (Suspicious)]',\n",
    "    'On a scale of 1 - 4, where 1 is \"Very well kept / good condition\" and 4 is \"Poor / badly deteriorated condition\", in general, how would you rate the condition of buildings on the block face? (includes residential buildings, recreational facilities, manufacturing plants, business / industrial headquarters, etc)' : 'Condition of Buildings [Scale: 1 (Well Kept) to 4 (Poor)]',\n",
    "    'On a scale of 1 - 4, where 1 is \"No fencing\" and 4 is \"High mesh fencing with barbed wire or spiked tops\", is there fencing and what kind? (includes all property)': 'Presence of Fencing [Scale: 1 (No fencing) to 4 (High mesh with barbed wire or spiked tops)]',\n",
    "    'On a scale of 1-3, where 1 is \"Few or none\" and 3 is a \"Most/all of it\", how many trees are linking the street of the block face? ': 'Amount of street linked with trees [Scale: 1 (None or Few) to 3 (Most or All)]',\n",
    "})\n",
    "\n",
    "class_data['What kinds of establishments are there on the block face? Select all that apply.'] = class_data['What kinds of establishments are there on the block face? Select all that apply.'].str.replace('Bodega, deli, corner-store, convenience store', 'Bodega deli corner-store convenience store')\n",
    "class_data['What kinds of establishments are there on the block face? Select all that apply.'] = class_data['What kinds of establishments are there on the block face? Select all that apply.'].str.replace('Payday lenders, check cashers, or pawn shops', 'Payday lenders check cashers or pawn shops')\n",
    "class_data['What kinds of establishments are there on the block face? Select all that apply.'] = class_data['What kinds of establishments are there on the block face? Select all that apply.'].str.replace('Professional offices \\(doctor, dentist, lawyer, accountant, real estate\\)', 'Professional offices (doctor dentist lawyer accountant real estate)')\n",
    "\n",
    "class_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some summary statistics and do some plotting.\n",
    "\n",
    "How many of you reported on which census tracts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data['Census Tract'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can use the `.plot.barh()` method to this to visualize the counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_data['Census Tract'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a short function, `bar_chart_column`, to plot the counts for any of our columns in the table. All we have to do is move the slider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart_column(column_num):\n",
    "    bar_chart_data[bar_chart_data.columns[column_num]].value_counts().plot.barh()\n",
    "    plt.title(bar_chart_data.columns[column_num])\n",
    "\n",
    "## Removes student identification information, drop questions with checkboxes\n",
    "bar_chart_data = class_data.iloc[:, 3:21].drop(\n",
    "    'What kinds of establishments are there on the block face? Select all that apply.',\n",
    "    axis = 1)\n",
    "\n",
    "slider = widgets.IntSlider(min=0, max=14,step=1,value=0)\n",
    "display(widgets.interactive(bar_chart_column, column_num=slider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the charts are small because there is so much text, try double-clicking the image to increase the size.\n",
    "\n",
    "We can then ask for these columns and plot their means too. Again, you'll have to double click to zoom in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data.iloc[:, 4:22].mean().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "One of the questions had checkbox answers that listed all of the establishments that were observed by each student in their assigned census tract. Let's create a seperate column for each of the possible options. A value of `1` in the column indicates that the estalishment was observed. A value of `0` indicates that the establishment was not observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishments = pd.Series([item for sublist in [response.split(', ') for response in class_data.iloc[:, 18]] for item in sublist])\n",
    "\n",
    "for establishment in establishments.unique():\n",
    "    establishment_data = []\n",
    "\n",
    "    for index, row in class_data.iterrows():\n",
    "        ests = row['What kinds of establishments are there on the block face? Select all that apply.']\n",
    "        row_establishments = ests.split(', ')\n",
    "        if establishment in row_establishments:\n",
    "            establishment_data.append(1)\n",
    "        else: \n",
    "            establishment_data.append(0)\n",
    "    \n",
    "    \n",
    "    class_data[establishment] = establishment_data\n",
    "    \n",
    "class_data.head().iloc[:,18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_sums = []\n",
    "for col in class_data.iloc[:, 19:].columns:\n",
    "    col_sums.append(sum(class_data.iloc[:, 19:][col]))\n",
    "\n",
    "establishment_counts = pd.Series(col_sums, index = class_data.iloc[:, 19:].columns)\n",
    "\n",
    "establishment_counts.plot.barh()\n",
    "plt.title(class_data.columns[18])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Mapping\n",
    "\n",
    "We can also visualize how your responses mapped out over the census tracts. We'll use a library called `folium` to map your observations onto a map of the census tracts, and include popups with your comments and photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alameda = geojson.load(open(\"data/alameda-2010.geojson\"))\n",
    "myMap = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "\n",
    "map_data(myMap, alameda, image_data).save(\"map1.html\")\n",
    "IFrame('map1.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click around census tracts near yours to see if the other students' observations are similar and see if you can eyeball any trends. Check out other areas on the map and see if there are trends for tracts in specific areas. Do specific characteristics cluster in different areas? Which ones? Which characteristsics seem to cluster together? What types of data do you think will correlate with socioeconomic characteristics like median income, poverty rate, education?  Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Our Metrics<a id='ourmetrics'></a>\n",
    "\n",
    "Now that you have made some predictions, we can compare our data with socioeconomic data from the U.S. Census for the different tracts we visited and see if we can find evidence to support them. From your data, we can create some point scales that measure different aspects of a neighborhood.\n",
    "\n",
    "For example, we can make a scale called “social disorder” for the first part of your responses. Let's first subeset our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_disorder = class_data.iloc[:, 3:13]\n",
    "social_disorder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to scale the values because all responses were not on the same scale. But for this part, the higher the value the more negative the social disorder was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_disorder = scale_values(social_disorder, list(range(1,10)))\n",
    "social_disorder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our values are scaled, we can take the mean across all observation for a given census tract for a given column, and then take the mean across columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_disorder = pd.DataFrame(social_disorder.groupby(\"Census Tract\").mean().mean(axis=1))\n",
    "social_disorder.columns = [\"Social Disorder\"]\n",
    "social_disorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the higher the value the more negative we perceived the census tract to be.\n",
    "\n",
    "We can do the same for our amenities part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = class_data.iloc[:, [3] + [14] + list(range(19,41))]\n",
    "amenities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain amenities are positive and indicate desirable conditions in a neighborhood. These characteristics include things like School or Daycares, and supermarkets. Let's create a Data Frame containing only positive amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_amentities = amenities[[\n",
    "    'Census Tract',\n",
    "    'Banks or credit unions',\n",
    "    'Chain retail stores',\n",
    "    'Community center',\n",
    "    'Eating places/restaurants',\n",
    "    'Fire station',\n",
    "    'Parks',\n",
    "    'Playgrounds',\n",
    "    'Police station',\n",
    "    'Public library',\n",
    "    'Post office',\n",
    "    'Professional offices (doctor dentist lawyer accountant real estate)',\n",
    "    'Schools or daycare centers',\n",
    "    'Supermarkets/grocery stores',\n",
    "    'Amount of street linked with trees [Scale: 1 (None or Few) to 3 (Most or All)]'\n",
    "]].rename(columns={'Amount of street linked with trees [Scale: 1 (None or Few) to 3 (Most or All)]': 'Trees'})\n",
    "\n",
    "positive_amentities['Trees'] = [0 if tree_count == 0 else 1 for tree_count in positive_amentities['Trees']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make positive amenities comparable between census tracts, we can find the mean of positive amenities for each census tract. A higher value indicates a more positive census tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_amentities = pd.DataFrame(positive_amentities.groupby(\"Census Tract\").mean().mean(axis=1))\n",
    "positive_amentities.columns = [\"Positive Amenities\"]\n",
    "positive_amentities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain amenities are negative and indicate undesirable conditions in a neighborhood. These characteristics include things like Bars or Fast Food Restaurants. Let's create a Data Frame with only negative amenities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_amentities = amenities[[\n",
    "    'Census Tract',\n",
    "    'Auto repair/auto body shop',\n",
    "    'Bars and alcoholic beverage services',\n",
    "    'Bodega deli corner-store convenience store',\n",
    "    'Fast food or take-out places',\n",
    "    'Gas station',\n",
    "    'Liquor stores or Marijuana Dispensaries',\n",
    "    'Manufacturing' ,\n",
    "    'Payday lenders check cashers or pawn shops',\n",
    "    'Warehouses'\n",
    "]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make negative amenities comparable between census tracts, we can find the mean of negative amenities for each census tract. A higher value indicates a more negative census tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_amentities = pd.DataFrame(negative_amentities.groupby(\"Census Tract\").mean().mean(axis=1))\n",
    "negative_amentities.columns = [\"Negative Amenities\"]\n",
    "negative_amentities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Census Data<a id='census'></a>\n",
    "\n",
    "Let's read in some data for census tracts from the [American FactFinder](https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_data = pd.DataFrame.from_csv(\"data/merged-census.csv\", index_col=None)\n",
    "official_data['Census Tract'] = official_data[\"Census Tract\"].apply(fix_tract)\n",
    "official_data = official_data.set_index(\"Census Tract\")\n",
    "official_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add our columns to this table to put it all in one place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "joined_data = official_data.join(social_disorder).join(positive_amentities).join(negative_amentities).reset_index()\n",
    "joined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mapping Exploration\n",
    "\n",
    "Before we quantify the relationship between the census data and our own metrics, let's do some exploratory mapping. We can now add our social disorder and amenities metrics to the popup too!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bachelor's Degree or higher %:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapc = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "IFrame('map4.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our \"social disorder\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapd = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "#choropleth_overlay(mapa=mapd, column_name=\"Social Disorder\", joined=joined_data, alameda=alameda).save(\"map5.html\")\n",
    "IFrame('map5.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, \"Negative Amenities\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "#choropleth_overlay(mapa=mapa, column_name=\"Negative Amenities\", joined=joined_data, alameda=alameda).save(\"map7.html\")\n",
    "IFrame('map7.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try copying and pasting one of the mapping cells above and change the `column_name` variable to a different variable (column in our data) you'd like to map, then run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Variable Distributions\n",
    "\n",
    "We can also visualize the distributions of these variables according to census tract with [histograms](https://en.wikipedia.org/wiki/Histogram). A histogram will create bins, or ranges, within a variable and then count up the frequency for that bin. If we look at household median income, we may have bins of $10,000, and then we'd count how many tracts fall within that bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_dist(var_name, tract):\n",
    "    x = joined_data[var_name].dropna()\n",
    "    reindexed = joined_data.set_index(\"Census Tract\")\n",
    "    \n",
    "    plt.hist(x)\n",
    "    plt.axvline(x=reindexed.loc[tract, var_name], color = \"RED\")\n",
    "    plt.xlabel(var_name, fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "display(widgets.interactive(viz_dist, var_name=list(joined_data.columns[1:]), tract=list(joined_data[\"Census Tract\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these distributions tell you?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Part 4: Correlation<a id='correlation'></a>\n",
    "\n",
    "Let's first analyze income levels. We have sorted the data according to income level. Compare the income levels to the level of social disorder and amenities. Is there a correlation you can spot(as one increases or decreases, does the other do the same)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.sort_values(\"Household Median Income\", ascending=False)[[\"Household Median Income\", \"Social Disorder\", \"Positive Amenities\", \"Negative Amenities\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you look at the whole table? A common mistake is to assume that since the top 10 results follow or do not follow a pattern, the rest don't. Real life data is often messy and not clean. Does the correlation continue throughout the whole table (a.k.a. as income decreases the points decrease) or is there no pattern? What does this mean about the data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Eyeballing patterns is not the same as a statisical measure of a correlation; you must quantify it with numbers and statistics to prove your thoughts. Looking at the tables is not a very statistical measure of how much a variable correlates to the results. What does it mean for a variable \"income\" to match 7 out of the top 15 social disorder points? Does this correlate to the rest of the results? How well does it correlate? \n",
    "\n",
    "### The correlation coefficient - *r*\n",
    "\n",
    "> The correlation coefficient ranges from −1 to 1. A value of 1 implies that a linear equation describes the relationship between X and Y perfectly, with all data points lying on a line for which Y increases as X increases. A value of −1 implies that all data points lie on a line for which Y decreases as X increases. A value of 0 implies that there is no linear correlation between the variables. ~Wikipedia\n",
    "\n",
    "*r* = 1: the scatter diagram is a perfect straight line sloping upwards\n",
    "\n",
    "*r* = -1: the scatter diagram is a perfect straight line sloping downwards.\n",
    "\n",
    "Let's calculate the correlation coefficient between acceleration and price. We can use the `corr` method to generate a correlation matrix of our `joined_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the matrix is mirrored with a `1.000000` going down the diagonal. This matrix yields the correlation coefficient for each variable to every other variable in our data.\n",
    "\n",
    "For example, if we look at the `Social Disorder`, we see that there is a `.487102` correlation, implying that there is a strong positive relationship between our constructed social disorder variable and the unemployment rate (i.e., as one goes up the other goes up too). What else do you notice?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Regression<a id='regression'></a>\n",
    "\n",
    "We will now use a method called linear regression to make a graph that will show the best fit line that correlates to the data. The slope of the line will show whether it is positively correlated or negatively correlated. The code that we've created so far has helped us establish a relationship between our two variables. Once a relationship has been established, it's time to create a model of the data. To do this we'll find the equation of the **regression line**!\n",
    "\n",
    "The regression line is the **best fit** line for our data. It’s like an average of where all the points line up. In linear regression, the regression line is a perfectly straight line! Below is a picture showing the best fit line.\n",
    "\n",
    "![image](http://onlinestatbook.com/2/regression/graphics/gpa.jpg)\n",
    "\n",
    "As you can infer from the picture, once we find the **slope** and the **y-intercept** we can start predicting values! The equation for the above regression to predict university GPA based on high school GPA would look like this:\n",
    "\n",
    "$UNIGPA_i= \\alpha + \\beta HSGPA + \\epsilon_i$\n",
    "\n",
    "The variable we want to predict (or model) is the left side `y` variable, the variable which we think has an influence on our left side variable is on the right side. The $\\alpha$ term is the y-intercept and the $\\epsilon_i$ describes the randomness.\n",
    "\n",
    "We can set up a visualization to choose which variables we want as `x` and `y` and then plot the line of best fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x_variable, y_variable):\n",
    "    \n",
    "    if \"median house value\" in [x_variable, y_variable]:\n",
    "        drop_na = joined_data.dropna()  # if not all census tracts have measure\n",
    "        x = drop_na[x_variable]\n",
    "        y = drop_na[y_variable]\n",
    "        \n",
    "    else:\n",
    "        x = joined_data[x_variable]\n",
    "        y = joined_data[y_variable]\n",
    "    \n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel(x_variable, fontsize=18)\n",
    "    plt.ylabel(y_variable, fontsize=18)\n",
    "    plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color=\"r\") #calculate line of best fit\n",
    "    plt.show()\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y) #gets the r_value\n",
    "    print(\"R-squared: \", r_value**2)\n",
    "    \n",
    "display(widgets.interactive(f, x_variable=list(joined_data)[1:], y_variable=list(joined_data)[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** The `R-squared` tells us how much of the variation in the data can be explained by our model.\n",
    "\n",
    "Why is this a better method than just sorting tables? First of all, we are now comparing all of the data in the graph to the variable, rather than comparing what our eyes glance quickly over. It shows a more complete picture than just saying \"There are some similar results in the top half of the sorted data\". Second of all, the graph gives a more intuitive sense to see if your variable does match the data. You can quickly see if the data points match up with the regression line. Lastly, the r-squared value will give you a way to quantify how good the variable is to explain the data.\n",
    "\n",
    "One of the beautiful things about computer science and statistics is that you do not need to reinvent the wheel. You don't need to know how to calculate the `R-squared` value, or draw the regression line; someone has already implemented it! You simply need to tell the computer to calculate it. However, if you are interested in these mathematical models, take a data science or statistics course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "***Please fill out our [feedback form](https://goo.gl/forms/PR1OQvX3bMIfype62)!***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
