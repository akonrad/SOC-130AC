{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below with the ▶| button above to set up this notebook, or type `SHIFT-ENTER`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir -U -q folium\n",
    "import pandas as pd\n",
    "import geojson\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from datascience import *\n",
    "from IPython.display import HTML, display, IFrame\n",
    "from folium import plugins\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "from scipy import stats\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from scripts.soc_module import *\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sociology 130AC Module: \"The Neighborhood Project\"\n",
    "\n",
    "Welcome to the data science part of your project! You have gathered data and entered it [here](https://goo.gl/forms/eY1mephilS6VqAT83) from your assigned census tracts.  Now it's time to explore our class data and quantify our observations using Python, a popular programming language used in data science. \n",
    "\n",
    "You won't need any prior programming knowledge to do this! The purpose of this module is not to teach you programming, but rather to show you the power of these tools and give you the intuition for how they work. It also allows us to quickly produce summarizations of our data!\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "0 - [Python and Jupyter Notebooks](#jupyter)\n",
    "\n",
    "1 - [Class Data](#yourdata)\n",
    "\n",
    "2 - [Our Metrics](#ourmetrics)\n",
    "\n",
    "3 - [Census Data](#census)\n",
    "\n",
    "4 - [Correlation](#correlation)\n",
    "\n",
    "5 - [Regression](#regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Introduction to Python and Jupyter Notebooks: <a id='jupyter'></a>\n",
    "\n",
    "## 1. Cells, Arithmetic, and Code\n",
    "In a notebook, each rectangle containing text or code is called a *cell*.\n",
    "\n",
    "Cells (like this one) can be edited by double-clicking on them. This cell is a text cell, written in a simple format called [Markdown](http://daringfireball.net/projects/markdown/syntax) to add formatting and section headings.  You don't need to worry about Markdown today, but it's a pretty fun+easy tool to learn.\n",
    "\n",
    "After you edit a cell, click the \"run cell\" button at the top that looks like ▶| to confirm any changes. (Try not to delete the instructions.) You can also press `SHIFT-ENTER` to run any cell or progress from one cell to the next.\n",
    "\n",
    "Other cells contain code in the Python programming language.  Running a code cell will execute all of the code it contains.\n",
    "\n",
    "Try running this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello, World!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now quickly go through some very basic functionality of Python, which we'll be using throughout the rest of this notebook.\n",
    "\n",
    "### 1.1 Arithmetic\n",
    "Quantitative information arises everywhere in data science. In addition to representing commands to `print` out lines, expressions can represent numbers and methods of combining numbers. \n",
    "\n",
    "The expression `3.2500` evaluates to the number 3.25. (Run the cell and see.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't necessarily always need to say \"`print`\", because Jupyter always prints the last line in a code cell. If you want to print more than one line, though, do specify \"`print`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(3)\n",
    "4\n",
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many basic arithmetic operations are built in to Python, like `*` (multiplication), `+` (addition), `-` (subtraction), and `/` (division). There are many others, which you can find information about [here](http://www.inferentialthinking.com/chapters/03/1/expressions.html). Use parenthesis to specify the order of operations, which act according to PEMDAS, just as you may have learned in school. Use parentheses for a happy new year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 + (6 * 5 - (6 * 3)) ** 2 * (( 2 ** 3 ) / 4 * 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Variables\n",
    "\n",
    "We sometimes want to work with the result of some computation more than once. To be able to do that without repeating code everywhere we want to use it, we can store it in a variable with *assignment statements*, which have the variable name on the left, an equals sign, and the expression to be evaluated and stored on the right. In the cell below, `(3 * 11 + 5) / 2 - 9` evaluates to 10, and gets stored in the variable `result`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (3 * 11 + 5) / 2 - 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functions\n",
    "\n",
    "    \n",
    "One important form of an expression is the call expression, which first names a function and then describes its arguments. The function returns some value, based on its arguments. Some important mathematical functions are:\n",
    "\n",
    "| Function | Description                                                   |\n",
    "|----------|---------------------------------------------------------------|\n",
    "| `abs`      | Returns the absolute value of its argument                    |\n",
    "| `max`      | Returns the maximum of all its arguments                      |\n",
    "| `min`      | Returns the minimum of all its arguments                      |\n",
    "| `round`    | Round its argument to the nearest integer                     |\n",
    "\n",
    "Here are two call expressions that both evaluate to 3\n",
    "\n",
    "```python\n",
    "abs(2 - 5)\n",
    "max(round(2.8), min(pow(2, 10), -1 * pow(2, 10)))\n",
    "```\n",
    "\n",
    "These function calls first evaluate the expressions in the arguments (inside the parentheses), then evaluate the function on the results. `abs(2-5)` evaluates first to `abs(3)`, then returns `3`.\n",
    "\n",
    "A **statement** is a whole line of code.  Some statements are just expressions, like the examples above, that can be broken down into its subexpressions which get evaluated individually before evaluating the statement as a whole.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Calling functions\n",
    "\n",
    "The most common way to combine or manipulate values in Python is by calling functions. Python comes with many built-in functions that perform common operations.\n",
    "\n",
    "For example, the `abs` function takes a single number as its argument and returns the absolute value of that number.  The absolute value of a number is its distance from 0 on the number line, so `abs(5)` is 5 and `abs(-5)` is also 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions can be called as above, putting the argument in parentheses at the end, or by using \"dot notation\", and calling the function after finding the arguments, as in the cell immediately below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = [1, 2, 5]  # a list of items, in this case, numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums.reverse()  # reverses the item order\n",
    "nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Class Data<a id='yourdata'></a>\n",
    "\n",
    "We can read in the data you submitted through the form by asking Google for the form information and turning it into a table. Any of the confusing lines here are just fixing data formats so that Python can better understand our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique key given by google for the csv\n",
    "gdoc_key = \"12yyTnaNi9JQqCqUqzP42iQDFV2jSiHffliUhrMfS__Y\"\n",
    "\n",
    "# we'll add the key to this url for google docs\n",
    "spreadsheet_url = 'https://docs.google.com/spreadsheets/d/{0}/gviz/tq?tqx=out:csv'.format(gdoc_key)\n",
    "\n",
    "# now we read in the spreadsheet to python, sum column tallies for column 20\n",
    "class_data = pd.read_csv(spreadsheet_url)\n",
    "class_data['Census Tract'] = class_data['Census Tract'].apply(fix_tract)  # fix census tract data type\n",
    "\n",
    "# rekey yes and no responses\n",
    "for c in class_data.columns:\n",
    "    if \"Yes\" in set(class_data[c]):\n",
    "        class_data[c] = class_data[c].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "class_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of columns! Now that our data is inside the `class_data` variable, we can ask that varible for some information. We can get a list of the column names with the `.columns` attribute of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask for the total number of observations (rows) by just using the `len` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some summary statistics and do some plotting.\n",
    "\n",
    "How many of you reported on which census tracts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data['Census Tract'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `.plot.barh()` method to this to visualize the counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_data['Census Tract'].value_counts().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a short function, `bar_chart_column`, to plot the counts for any of our columns in the table. All we have to do is move the slider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart_column(column_num):\n",
    "    class_data[class_data.columns[column_num]].value_counts().plot.barh()\n",
    "    plt.title(class_data.columns[column_num])\n",
    "\n",
    "slider = widgets.IntSlider(min=3,max=len(class_data.columns)-1,step=1,value=3)\n",
    "display(widgets.interactive(bar_chart_column, column_num=slider))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the charts are small because there is so much text, try double-clicking the image to increase the size.\n",
    "\n",
    "We can then ask for these columns and plot their means too. Again, you'll have to double click to zoom in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data.iloc[:, 4:].mean().plot.barh()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple questions had checkbox answers that we can also look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishments = [item for sublist in [response.split(',') for response in class_data.iloc[:, 15]] for item in sublist]\n",
    "pd.DataFrame(establishments)[0].value_counts().plot.barh()\n",
    "plt.title(class_data.columns[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "establishments = [item for sublist in [response.split(',') for response in class_data.iloc[:, 17]] for item in sublist]\n",
    "pd.DataFrame(establishments)[0].value_counts().plot.barh()\n",
    "plt.title(class_data.columns[17])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Mapping\n",
    "\n",
    "We can also visualize how your responses mapped out over the census tracts. We'll use a library called `folium` to map your observations onto a map of the census tracts, and include popups with your comments and photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alameda = geojson.load(open(\"data/alameda-2010.geojson\"))\n",
    "myMap = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "map_data(myMap, alameda, class_data).save(\"map1.html\")\n",
    "IFrame('map1.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click around census tracts near yours to see if the other students' observations are similar and see if you can eyeball any trends. Check out other areas on the map and see if there are trends for tracts in specific areas. Do specific characteristics cluster in different areas? Which ones? Which characteristsics seem to cluster together? What types of data do you think will correlate with socioeconomic characteristics like median income, poverty rate, education?  Why?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Our Metrics<a id='ourmetrics'></a>\n",
    "\n",
    "Now that you have made some predictions, we can compare our data with socioeconomic data from the U.S. Census for the different tracts we visited and see if we can find evidence to support them. From your data, we can create some point scales that measure different aspects of a neighborhood.\n",
    "\n",
    "For example, we can make a scale called “social disorder” for the first part of your responses. Let's first subeset our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_disorder = class_data.iloc[:, 3:13]\n",
    "social_disorder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to scale the values because all responses were not on the same scale. But for this part, the higher the value the more negative the social disorder was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_disorder = scale_values(social_disorder, list(range(1,10)))\n",
    "social_disorder.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our values are scaled, we can take the mean across all observation for a given census tract for a given column, and then take the mean across columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_disorder = pd.DataFrame(social_disorder.groupby(\"Census Tract\").mean().mean(axis=1))\n",
    "social_disorder.columns = [\"Social Disorder\"]\n",
    "social_disorder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the higher the value the more negative we perceived the census tract to be.\n",
    "\n",
    "We can do the same for our amenities part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities = class_data.iloc[:, [3] + list(range(13,21))]\n",
    "amenities.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two of our questions had choices as checkboxes. These were generally good things to have around, so we'll just count the number of checked boxes and have that as our observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_checkboxes(response):\n",
    "    return len(response.split(','))\n",
    "\n",
    "amenities[amenities.columns[3]] = amenities[amenities.columns[3]].apply(count_checkboxes)\n",
    "amenities[amenities.columns[5]] = amenities[amenities.columns[5]].apply(count_checkboxes)\n",
    "\n",
    "amenities = scale_values(amenities, list(range(1,9)))\n",
    "\n",
    "\n",
    "amenities = pd.DataFrame(amenities.groupby(\"Census Tract\").mean().mean(axis=1))\n",
    "amenities.columns = [\"Amenities\"]\n",
    "amenities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, above, for amenities, a higher value is a more positive census tract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Census Data<a id='census'></a>\n",
    "\n",
    "Let's read in some data for census tracts from the [American FactFinder](https://factfinder.census.gov/faces/nav/jsf/pages/index.xhtml):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "official_data = pd.DataFrame.from_csv(\"data/merged-census.csv\", index_col=None)\n",
    "official_data['Census Tract'] = official_data[\"Census Tract\"].apply(fix_tract)\n",
    "official_data = official_data.set_index(\"Census Tract\")\n",
    "official_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add our columns columns to this table to put it all in one place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "joined_data = official_data.join(social_disorder).join(amenities).reset_index()\n",
    "joined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Mapping Exploration\n",
    "\n",
    "Before we quantify the relationship between the census data and our own metrics, let's do some exploratory mapping. We can now add our social disorder and amenities metrics to the popup too!\n",
    "\n",
    "First we'll map a choropleth of unemployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "choropleth_overlay(mapa=mapa, column_name=\"Unemployment %\", joined=joined_data, alameda=alameda, obs_data=class_data).save(\"map2.html\")\n",
    "IFrame('map2.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Household Median Income:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapb = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "choropleth_overlay(mapa=mapb, column_name=\"Household Median Income\", joined=joined_data, alameda=alameda, obs_data=class_data).save(\"map3.html\")\n",
    "IFrame('map3.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bachelor's Degree or higher %:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapc = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "choropleth_overlay(mapa=mapc, column_name=\"Bachelor's Degree or higher %\", joined=joined_data, alameda=alameda, obs_data=class_data).save(\"map4.html\")\n",
    "IFrame('map4.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our \"social disorder\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapd = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "choropleth_overlay(mapa=mapd, column_name=\"Social Disorder\", joined=joined_data, alameda=alameda, obs_data=class_data).save(\"map5.html\")\n",
    "IFrame('map5.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally \"amenities\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapa = folium.Map(location=(37.8044, -122.2711), zoom_start=11.4)\n",
    "choropleth_overlay(mapa=mapa, column_name=\"Amenities\", joined=joined_data, alameda=alameda, obs_data=class_data).save(\"map6.html\")\n",
    "IFrame('map6.html', width=700, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try copying and pasting one of the mapping cells above and change the `column_name` variable to a different variable (column in our data) you'd like to map, then run the cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Variable Distributions\n",
    "\n",
    "We can also visualize the distributions of these variables according to census tract with [histograms](https://en.wikipedia.org/wiki/Histogram). A histogram will create bins, or ranges, within a variable and then count up the frequency for that bin. If we look at household median income, we may have bins of $10,000, and then we'd count how many tracts fall within that bin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz_dist(var_name, tract):\n",
    "    x = joined_data[var_name].dropna()\n",
    "    reindexed = joined_data.set_index(\"Census Tract\")\n",
    "    \n",
    "    plt.hist(x)\n",
    "    plt.axvline(x=reindexed.loc[tract, var_name], color = \"RED\")\n",
    "    plt.xlabel(var_name, fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "display(widgets.interactive(viz_dist, var_name=list(joined_data.columns[1:]), tract=list(joined_data[\"Census Tract\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do these distributions tell you?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "# Part 4: Correlation<a id='correlation'></a>\n",
    "\n",
    "Let's first analyze income levels. We have sorted the data according to income level. Compare the income levels to the level of social disorder and amenities. Is there a correlation you can spot(as one increases or decreases, does the other do the same)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.sort_values(\"Household Median Income\", ascending=False)[[\"Household Median Income\", \"Social Disorder\", \"Amenities\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you look at the whole table? A common mistake is to assume that since the top 10 results follow or do not follow a pattern, the rest don't. Real life data is often messy and not clean. Does the correlation continue throughout the whole table (a.k.a. as income decreases the points decrease) or is there no pattern? What does this mean about the data?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Eyeballing patterns is not the same as a statisical measure of a correlation; you must quantify it with numbers and statistics to prove your thoughts. Looking at the tables is not a very statistical measure of how much a variable correlates to the results. What does it mean for a variable \"income\" to match 7 out of the top 15 social disorder points? Does this correlate to the rest of the results? How well does it correlate? \n",
    "\n",
    "### The correlation coefficient - *r*\n",
    "\n",
    "> The correlation coefficient ranges from −1 to 1. A value of 1 implies that a linear equation describes the relationship between X and Y perfectly, with all data points lying on a line for which Y increases as X increases. A value of −1 implies that all data points lie on a line for which Y decreases as X increases. A value of 0 implies that there is no linear correlation between the variables. ~Wikipedia\n",
    "\n",
    "*r* = 1: the scatter diagram is a perfect straight line sloping upwards\n",
    "\n",
    "*r* = -1: the scatter diagram is a perfect straight line sloping downwards.\n",
    "\n",
    "Let's calculate the correlation coefficient between acceleration and price. We can use the `corr` method to generate a correlation matrix of our `joined_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the matrix is mirrored with a `1.000000` going down the diagonal. This matrix yields the correlation coefficient for each variable to every other variable in our data.\n",
    "\n",
    "For example, if we look at the `Social Disorder`, we see that there is a `.487102` correlation, implying that there is a strong positive relationship between our constructed social disorder variable and the unemployment rate (i.e., as one goes up the other goes up too). What else do you notice?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Regression<a id='regression'></a>\n",
    "\n",
    "We will now use a method called linear regression to make a graph that will show the best fit line that correlates to the data. The slope of the line will show whether it is positively correlated or negatively correlated. The code that we've created so far has helped us establish a relationship between our two variables. Once a relationship has been established, it's time to create a model of the data. To do this we'll find the equation of the **regression line**!\n",
    "\n",
    "The regression line is the **best fit** line for our data. It’s like an average of where all the points line up. In linear regression, the regression line is a perfectly straight line! Below is a picture showing the best fit line.\n",
    "\n",
    "![image](http://onlinestatbook.com/2/regression/graphics/gpa.jpg)\n",
    "\n",
    "As you can infer from the picture, once we find the **slope** and the **y-intercept** we can start predicting values! The equation for the above regression to predict university GPA based on high school GPA would look like this:\n",
    "\n",
    "$UNIGPA_i= \\alpha + \\beta HSGPA + \\epsilon_i$\n",
    "\n",
    "The variable we want to predict (or model) is the left side `y` variable, the variable which we think has an influence on our left side variable is on the right side. The $\\alpha$ term is the y-intercept and the $\\epsilon_i$ describes the randomness.\n",
    "\n",
    "We can set up a visualization to choose which variables we want as `x` and `y` and then plot the line of best fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x_variable, y_variable):\n",
    "    \n",
    "    if \"median house value\" in [x_variable, y_variable]:\n",
    "        drop_na = joined_data.dropna()  # if not all census tracts have measure\n",
    "        x = drop_na[x_variable]\n",
    "        y = drop_na[y_variable]\n",
    "        \n",
    "    else:\n",
    "        x = joined_data[x_variable]\n",
    "        y = joined_data[y_variable]\n",
    "    \n",
    "    plt.scatter(x, y)\n",
    "    plt.xlabel(x_variable, fontsize=18)\n",
    "    plt.ylabel(y_variable, fontsize=18)\n",
    "    plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), color=\"r\") #calculate line of best fit\n",
    "    plt.show()\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y) #gets the r_value\n",
    "    print(\"R-squared: \", r_value**2)\n",
    "    \n",
    "display(widgets.interactive(f, x_variable=list(joined_data)[1:], y_variable=list(joined_data)[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** The `R-squared` tells us how much of the variation in the data can be explained by our model.\n",
    "\n",
    "Why is this a better method than just sorting tables? First of all, we are now comparing all of the data in the graph to the variable, rather than comparing what our eyes glance quickly over. It shows a more complete picture than just saying \"There are some similar results in the top half of the sorted data\". Second of all, the graph gives a more intuitive sense to see if your variable does match the data. You can quickly see if the data points match up with the regression line. Lastly, the r-squared value will give you a way to quantify how good the variable is to explain the data.\n",
    "\n",
    "One of the beautiful things about computer science and statistics is that you do not need to reinvent the wheel. You don't need to know how to calculate the `R-squared` value, or draw the regression line; someone has already implemented it! You simply need to tell the computer to calculate it. However, if you are interested in these mathematical models, take a data science or statistics course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "***Please fill out our [feedback form](https://goo.gl/forms/PR1OQvX3bMIfype62)!***"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
